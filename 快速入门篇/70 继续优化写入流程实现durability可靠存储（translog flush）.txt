再次优化的写入流程

（1）数据写入buffer缓冲和translog日志文件
（2）每隔1秒，buffer中的数据被写入新的segment file，并进入os cache，此时的segment被打开供search使用
（3）buffer被清空
（4）重复1~3，新的segmeng不断添加，buffer不断被清空，而translog中的数据不断累加
（5）当translog长度达到一定程度的时候，commit操作发生
（5-1）buffer中的所有数据写入一个新的segment，并写入os cache，打开供使用
（5-2）buffer被清空
（5-3）一个commit point被写入磁盘，标明了所有的index segment
（5-4）filesystem cache中的所有index segment file缓存数据，被fsync强行刷到磁盘上
（5-5）现有的translog被清空，创建一个新的translog

基于translog和commit point，如何进行数据恢复

fsync+清空translog，就是flush，默认每隔30分钟flush一次，或者当translog过大的时候，也会flush

机器被重启，os disk上的数据并没有丢失，此时就会将translog文件中的变更记录进行回放，重新执行之前的各种操作，在buffer中执行，重新刷一个一个的segment到os cache中，等待下一次commit发生即可

POST /my_index/_flush 手动flush，一般来说别手动flush，让它自动去执行就可以了

translog，每隔5秒被fsync一次到磁盘上，在一次增删改操作之后，当fsync在primary shard和replica shard都成功之后，那次增删改操作才会成功

但是这种在一次增删改时强行fsync translog可能会导致部分操作比较耗时，（最多还是可能丢失5秒内的数据），如果允许部分数据丢失，可以设置异步fsync translog

PUT /my_index/_settings
{
	"index.translog.durability" : "async",  异步执行fsync translog
	"index.translog.sync_interval" : "5s"
}